var documenterSearchIndex = {"docs":
[{"location":"#Robustbase.jl","page":"Robustbase.jl","title":"Robustbase.jl","text":"","category":"section"},{"location":"","page":"Robustbase.jl","title":"Robustbase.jl","text":"Documentation for Robustbase.jl","category":"page"},{"location":"#Univariate:-Robust-scales","page":"Robustbase.jl","title":"Univariate: Robust scales","text":"","category":"section"},{"location":"","page":"Robustbase.jl","title":"Robustbase.jl","text":"The univariate module contains several univariate location and scale estimators.  They all implement the abstract base class RobustScale, which has the properties location and scale and can be fitted using the fit! method. Each  class is expected to implement a _calculate method where the attributes scale_ and location_ are set.","category":"page"},{"location":"#Tau-scale","page":"Robustbase.jl","title":"Tau scale","text":"","category":"section"},{"location":"#Robustbase.Tau","page":"Robustbase.jl","title":"Robustbase.Tau","text":"Tau <: RobustScale\n\nTau(; c1::Float64=4.5, c2::Float64=3.0, consistency_correction::Bool=true, can_handle_nan::Bool=false)\n\nRobust Tau-Estimate of Scale\n\nComputes the robust τ-estimate of univariate scale, as proposed by Maronna and Zamar (2002); improved by a consistency factor\n\nKeywords\n\n`c1::Float64=4.5`, optional: constant for the weight function, defaults to 4.5\n`c2::Float64=3.0`, optional: constant for the rho function, defaults to 3.0\n`consistency_correction::Bool`, optional: boolean indicating if consistency for normality should be applied. Defaults to True.\n`can_handle_nan::Bool`, optional: boolean indicating whether NANs can be handled, defaults to false.\n\nReferences\n\nRobust Estimates of Location and Dispersion for High-Dimensional Datasets,\nRicarco A Maronna and Ruben H Zamar (2002)\n\nExamples\n\njulia> x = hbk[:,1];\njulia> tau = Tau();\njulia> fit!(tau, x);\njulia> location(tau)\n1.5554543865072337\n\njulia> scale(tau)\n2.012461881814477\n\n\n\n\n\n","category":"type"},{"location":"#Qn-scale","page":"Robustbase.jl","title":"Qn scale","text":"","category":"section"},{"location":"#Robustbase.Qn","page":"Robustbase.jl","title":"Robustbase.Qn","text":"Qn <: RobustScale\n\nQn(;location_func::Function=median, consistency_correction::Bool=true, finite_correction::Bool=true, can_handle_nan::Bool = false)\n\nRobust Location-Free Scale Estimate More Efficient than MAD\n\nKeywords\n\n`location_func::LocationOrScaleEstimator`, optional: as the Qn estimator does not\n    estimate location, a location function should be explicitly passed.\n`consistency_correction::Bool`, optional: boolean indicating if consistency for normality should be applied. Defaults to true.\n`finite_correction::Bool`, optional: boolean indicating if finite sample correction should be applied. Defaults to true.\n\nReferences\n\nChristophe Croux and Peter J. Rousseeuw (1992). Time-efficient algorithms for two highly robust estimators of scale.\n\nDonald B. Johnson and Tetsuo Mizoguchi (1978). Selecting the k^th element in X+Y and X1+...+Xm\n\nExamples\n\njulia> x = hbk[:,1];\n\njulia> qn = Qn();\njulia> fit!(qn, x);\n\njulia> location(qn)         # the median\n1.8\n\njulia> scale(qn)\n1.7427832460732984\n\n\n\n\n\n","category":"type"},{"location":"#Location","page":"Robustbase.jl","title":"Location","text":"","category":"section"},{"location":"#Robustbase.location","page":"Robustbase.jl","title":"Robustbase.location","text":"location(rs::RobustScale)\n\nUnivariate location\n\n\n\n\n\nlocation(model::CovarianceEstimator)::Vector{Float64}\n\nLocation vector\n\n\n\n\n\n","category":"function"},{"location":"#Scale","page":"Robustbase.jl","title":"Scale","text":"","category":"section"},{"location":"#Robustbase.scale","page":"Robustbase.jl","title":"Robustbase.scale","text":"scale(rs::RobustScale)\n\nUnivariate scale\n\n\n\n\n\n","category":"function"},{"location":"#Multivariate:-Covariance","page":"Robustbase.jl","title":"Multivariate: Covariance","text":"","category":"section"},{"location":"","page":"Robustbase.jl","title":"Robustbase.jl","text":"Various robust estimators of covariance matrices (\"scatter matrices\") have been proposed in the literature, with different properties. The covariance module implements several frequently used scatter estimators. They all use the new base class RobustCovariance which builds on the CovarianceEstimator class in StatsBase.","category":"page"},{"location":"#Classical-Location-and-Scatter-Estimation:-CovClassic","page":"Robustbase.jl","title":"Classical Location and Scatter Estimation: CovClassic","text":"","category":"section"},{"location":"#Robustbase.CovClassic","page":"Robustbase.jl","title":"Robustbase.CovClassic","text":"CovClassic <: CovarianceEstimator <: Any\n\nCovClassic(;assume_centered=false)\n\nClassical Location and Scatter Estimation\n\nCompute the classical estimetas of the location vector and covariance matrix of a data matrix.\n\nExamples\n\njulia> cc=CovClassic();\njulia> fit!(cc, hbk[:,1:3])\n-> Method:  Classical Estimator. \n\nEstimate of location:\n[3.20667, 5.59733, 7.23067]\n\nEstimate of covariance:\n3×3 Matrix{Float64}:\n 13.3417  28.4692   41.244\n 28.4692  67.883    94.6656\n 41.244   94.6656  137.835\n\n\n\n\n\n","category":"type"},{"location":"#Covariance-matrix:-covariance","page":"Robustbase.jl","title":"Covariance matrix: covariance","text":"","category":"section"},{"location":"#Robustbase.covariance","page":"Robustbase.jl","title":"Robustbase.covariance","text":"covariance(model::CovarianceEstimator)::Matrix{Float64}\n\nCovariance matrix\n\n\n\n\n\n","category":"function"},{"location":"#Correlation-matrix:-correlation","page":"Robustbase.jl","title":"Correlation matrix: correlation","text":"","category":"section"},{"location":"#Robustbase.correlation","page":"Robustbase.jl","title":"Robustbase.correlation","text":"correlation(model::CovarianceEstimator)::Matrix{Float64}\n\nCorrelation matrix\n\n\n\n\n\n","category":"function"},{"location":"#Robust-Location-and-Scatter-Estimation-via-MCD:-CovMcd","page":"Robustbase.jl","title":"Robust Location and Scatter Estimation via MCD: CovMcd","text":"","category":"section"},{"location":"#Robustbase.CovMcd","page":"Robustbase.jl","title":"Robustbase.CovMcd","text":"CovMcd <: RobustCovariance <: CovarianceEstimator \n\nCovMcd(;assume_centered=false, alpha=nothing, n_initial_subsets=500, n_initial_c_steps=2,\n    n_best_subsets=10, n_partitions=nothing, tolerance=1e-8, reweighting=true, verbosity=Logging.Warn)\n\nRobust Location and Scatter Estimation via MCD\n\nCompute the Minimum Covariance Determinant (MCD) estimator, a robust multivariate location and scale  estimate with a high breakdown point, via the 'Fast MCD' algorithm proposed in Rousseeuw and Van Driessen (1999).\n\nKeywords:\n\n`alpha::Float64 | Int | Nothing`, optional:\n    size of the h subset.\n    If an integer between n/2 and n is passed, it is interpreted as an absolute value.\n    If a float between 0.5 and 1 is passed, it is interpreted as a proportation\n    of n (the training set size).\n    If None, it is set to (n+p+1) / 2.\n    Defaults to Nothing.\n`n_initial_subsets::Int`, optional: number of initial random subsets of size p+1\n`n_initial_c_steps::Int`, optional: number of initial c steps to perform on all initial subsets\n`n_best_subsets::Int`, optional: number of best subsets to keep and perform c steps on until convergence\n`n_partitions::Int` optional: Number of partitions to split the data into.\n    This can speed up the algorithm for large datasets (n > 600 suggested in paper)\n    If None, 5 partitions are used if n > 600, otherwise 1 partition is used.\n`tolerance::Float64`, optional: Minimum difference in determinant between two iterations to stop the C-step\n`reweighting:Bool`, optional: Whether to apply reweighting to the raw covariance estimate\n\nReferences:\n\nRousseeuw and Van Driessen, A Fast Algorithm for the Minimum Covariance Determinant\nEstimator, 1999, American Statistical Association and\nthe American Society for Quality, TECHNOMETRICS\n\nExamples\n\njulia> mcd=CovMcd();\njulia> fit!(mcd, hbk[:,1:3])\n-> Method:  Fast MCD Estimator: (alpha=nothing ==> h=39)\n\nRobust estimate of location:\n[1.55833, 1.80333, 1.66]\n\nRobust estimate of covariance:\n3×3 Matrix{Float64}:\n 1.21312    0.0239154  0.165793\n 0.0239154  1.22836    0.195735\n 0.165793   0.195735   1.12535\n\njuilia> dd_plot(mcd)\n\n\n\n\n\n","category":"type"},{"location":"#Deterministic-MCD-estimator:-DetMCD","page":"Robustbase.jl","title":"Deterministic MCD estimator: DetMCD","text":"","category":"section"},{"location":"#Robustbase.DetMcd","page":"Robustbase.jl","title":"Robustbase.DetMcd","text":"DetMcd(; assume_centered=false,  alpha=nothing, n_maxcsteps=200, tolerance=1e-8,\n    reweighting=true, verbosity=Logging.Warn)\n\nDeterministic MCD estimator (DetMCD) based on the algorithm proposed in Hubert, Rousseeuw and Verdonck (2012)\n\nKeywords:\n\n`alpha::Float64 | Int | Nothing`, optional: size of the h subset.\n    If an integer between n/2 and n is passed, it is interpreted as an absolute value.\n    If a float between 0.5 and 1 is passed, it is interpreted as a proportation\n    of n (the training set size).\n    If None, it is set to (n+p+1) / 2.\n    Defaults to None.\n`n_maxcsteps::Int=200`, optional: Maximum number of C-step iterations\n`tolerance::Float64`, optional: Minimum difference in determinant between two iterations to stop the C-step\n`reweighting::Bool`, optional: Whether to apply reweighting to the raw covariance estimate\n\nReferences:\n\nHubert, Rousseeuw and Verdonck, A deterministic algorithm for robust location\nand scatter, 2012, Journal of Computational and Graphical Statistics\n\nExamples\n\njulia> mcd=DetMcd();\njulia> fit!(mcd, hbk[:,1:3])\n-> Method:  Deterministic MCD: (alpha=nothing ==> h=39)\n\nRobust estimate of location:\n[1.5377, 1.78033, 1.68689]\n\nRobust estimate of covariance:\n3×3 Matrix{Float64}:\n 1.2209     0.0547372  0.126544\n 0.0547372  1.2427     0.151783\n 0.126544   0.151783   1.15414\n\njulia> dd_plot(mcd);\n\n\n\n\n\n","category":"type"},{"location":"#Orthogonalized-Gnanadesikan-Kettenring-estimator:-CovOgk","page":"Robustbase.jl","title":"Orthogonalized Gnanadesikan-Kettenring estimator: CovOgk","text":"","category":"section"},{"location":"#Robustbase.CovOgk","page":"Robustbase.jl","title":"Robustbase.CovOgk","text":"CovOgk(;store_precision::Bool=true, assume_centered::Bool=false, location_estimator::Function=median,\n    scale_estimator::Function=MAD_scale, n_iterations::Int=2, reweighting::Bool=false,\n    reweighting_beta::Float64=0.9)\n\nImplementation of the Orthogonalized Gnanadesikan-Kettenring estimator for location dispersion proposed in Maronna, R. A., & Zamar, R. H. (2002)\n\nKeywords:\n\nstore_precision (boolean, optional): whether to store the precision matrix\nassume_centered (boolean, optional): whether the data is already centered\nlocation_estimator (LocationOrScaleEstimator, optional): function to estimate the\n    location of the data, should accept an array like input as first value and a named\n    argument axis\nscale_estimator (LocationOrScaleEstimator, optional): function to estimate the scale\n    of the data, should accept an array like input as first value and a named argument\n    axis\nn_iterations (int, optional): number of iteration for orthogonalization step\nreweighting (boolean, optional): whether to apply reweighting at the end\n    (i.e. calculating regular location and covariance after filtering outliers based on\n    Mahalanobis distance using OGK estimates)\nreweighting_beta (float, optional): quantile of chi2 distribution to use as cutoff for\n    reweighting\n\nReferences:\n\nMaronna, R. A., & Zamar, R. H. (2002).\nRobust Estimates of Location and Dispersion for High-Dimensional Datasets.\nTechnometrics, 44(4), 307–317. http://www.jstor.org/stable/1271538\n\nExamples\n\njulia> ogk=CovOgk();\njulia> fit!(ogk, hbk[:,1:3])\n-> Method:  Orthogonalized Gnanadesikan-Kettenring Estimator\n\nRobust estimate of location:\n[1.56005, 2.22345, 2.12035]\n\nRobust estimate of covariance:\n3×3 Matrix{Float64}:\n 3.3575    0.587449  0.699388\n 0.587449  2.09268   0.285757\n 0.699388  0.285757  2.77527\n\njulia> dd_plot(ogk);\n\n\n\n\n\n","category":"type"},{"location":"#Data-sets","page":"Robustbase.jl","title":"Data sets","text":"","category":"section"},{"location":"","page":"Robustbase.jl","title":"Robustbase.jl","text":"Robustbase includes several datasets that are often used in the robustness literature. These datasets serve as standard examples and benchmarks, allowing users to easily test robust algorithms. They are also available in the R-packages robustbase and rrcov.","category":"page"},{"location":"#Hawkings-and-Bradu-and-Kass-data","page":"Robustbase.jl","title":"Hawkings & Bradu & Kass data","text":"","category":"section"},{"location":"#Robustbase.DataSets.hbk","page":"Robustbase.jl","title":"Robustbase.DataSets.hbk","text":"Hawkins & Bradu & Kass data\n\nComponents\n\nx1::Float64: first independent variable.\nx2::Float64: second independent variable.\nx3::Float64: third independent variable.\ny::Float64: dependent (response) variable.\n\nReference\n\nHawkins, D.M., Bradu, D., and Kass, G.V. (1984) Location of several outliers in multiple regression data using elemental sets. Technometrics 26, 197–208.\n\n\n\n\n\n","category":"constant"},{"location":"#Animals-data","page":"Robustbase.jl","title":"Animals data","text":"","category":"section"},{"location":"#Robustbase.DataSets.animals","page":"Robustbase.jl","title":"Robustbase.DataSets.animals","text":"Animals data\n\nComponents\n\nnames::AbstractString: names of animals.\nbody::Float64: body weight in kg.\nbrain::Float64: brain weight in g.\n\nReferences\n\n Venables, W. N. and Ripley, B. D. (1999) _Modern Applied\n Statistics with S-PLUS._ Third Edition. Springer.\n\n P. J. Rousseeuw and A. M. Leroy (1987) _Robust Regression and\n Outlier Detection._ Wiley, p. 57.\n\n\n\n\n\n","category":"constant"},{"location":"#Stack-Loss-data","page":"Robustbase.jl","title":"Stack Loss data","text":"","category":"section"},{"location":"#Robustbase.DataSets.stackloss","page":"Robustbase.jl","title":"Robustbase.DataSets.stackloss","text":"Stack loss data\n\nComponents\n\nairflow::Float64: flow of cooling air (independent variable).\nwatertemp::Float64: cooling water inlet temperature (independent variable).\nacidcond::Float64: concentration of acid (independent variable).\nstackloss::Float64: stack loss (dependent variable).\n\nOutliers\n\nObservations 1, 3, 4, and 21 are outliers.\n\nReferences\n\nBecker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S Language_.  Wadsworth & Brooks/Cole.\n\nDodge, Y. (1996) The guinea pig of multiple regression. In: _Robust Statistics, Data Analysis, and Computer Intensive Methods;\nIn Honor of Peter Huber's 60th Birthday_, 1996, _Lecture Notes in Statistics_ *109*, Springer-Verlag, New York.\n\n\n\n\n\n","category":"constant"},{"location":"#Modified-Wood-Gravity-data","page":"Robustbase.jl","title":"Modified Wood Gravity data","text":"","category":"section"},{"location":"#Robustbase.DataSets.wood","page":"Robustbase.jl","title":"Robustbase.DataSets.wood","text":"Modified Wood Gravity Data\n\nComponents\n\nx1::Float64: Random values.\nx2::Float64: Random values.\nx3::Float64: Random values.\nx4::Float64: Random values.\nx5::Float64: Random values.\ny::Float64: Random values (independent variable).\n\nReferences\n\nP. J. Rousseeuw and A. M. Leroy (1987) Robust Regression and Outlier Detection. Wiley, p.243, table 8.\n\n\n\n\n\n","category":"constant"}]
}
